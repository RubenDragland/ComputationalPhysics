{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and matplotlib, and use jupyter magic to\n",
    "# get plots directly in notebook\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time, sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some general concepts: map and reduce\n",
    "\n",
    "\n",
    "### Map\n",
    "A map is essentially a function that takes some input, and produces some output (as most functions do), thus mapping from an input space to an output space.\n",
    "\n",
    "Python provides a built-in function called `map` which applies another function to a list of arguments. Note that this is shown here mainly as an example of the concept of mapping from input to output, not because it is a particularly good idea to use `map`. You can usually find more readable ways to do the same.\n",
    "\n",
    "### Reduce\n",
    "A reduction uses an associative operation (associative means order of operands doesn't matter) to reduce a list of inputs to a single value. Common examples include taking the sum of a list of numbers, or a product of a list of numbers.\n",
    "\n",
    "Python provides a function called `reduce` from the module `functools`. It takes a binary function (a function of two arguments), and applies it repeatedly to a list of inputs until one one value remains. Again, I include this here mainly as an example of the concept of reducing a list of inputs, not because it is a particularly good idea to use `reduce`. You can usually find more readable ways to do the same.\n",
    "\n",
    "### MapReduce\n",
    "Problems that can be formulated as a mapping and a reduction can sometimes be parallelised efficiently. The idea is that the mapping part, which usually takes the most time, can be distributed across processors, or even across different machines on a network, while the reduction part is usually fast, and since a reduction uses an associative operation, it doesn't matter in what order the results of the mapping are ready.\n",
    "\n",
    "An example might be that you analyse a set of images from an experiment, where you only care about the total number of particles seen in all the images. The mapping operation takes an image as input, and produces a single number (the particle count) as output. The reduction then just consists of keeping a running total of the counts when they are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "def doubler(x):\n",
    "    return 2*x\n",
    "\n",
    "inputs = np.arange(10)\n",
    "\n",
    "# Produce list of outputs using map\n",
    "# (map returns an iterable, not a list, so converting explicitly)\n",
    "outputs = list(map(doubler, inputs))\n",
    "print(outputs)\n",
    "\n",
    "# Produce the same list of outputs using list comprehension\n",
    "outputs = [doubler(x) for x in inputs]\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "add expected 2 arguments, got 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-145da8b356bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# The add function takes exactly two arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#add(5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: add expected 2 arguments, got 3"
     ]
    }
   ],
   "source": [
    "from functools import reduce \n",
    "from operator import add\n",
    "\n",
    "# The add function is equivalent to '+', but in function form.\n",
    "print(5+5)\n",
    "print(add(5,5))\n",
    "\n",
    "# The add function takes exactly two arguments\n",
    "# add(5)\n",
    "add(5, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total = 45\n",
      "Total = 45\n"
     ]
    }
   ],
   "source": [
    "inputs = np.arange(10)\n",
    "\n",
    "# Apply the add operator to the list of inputs\n",
    "total = reduce(add, inputs)\n",
    "print(f'Total = {total}')\n",
    "\n",
    "# You can achieve the same with the built-in sum function\n",
    "total = sum(inputs)\n",
    "print(f'Total = {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching several copies of a Python script from another script or notebook\n",
    "\n",
    "There are many different ways to launch multiple copies of a python script (or other program, for that matter). I you just need to run a few simulations, for a few different parameters, it might be easiest to just launch them manually. For more simulations, or if you want to run systematically for a range of input parameters, it might make more sense to set up some scheme for automatically launching simulations. Shell script can be a good tool for this, or you can launch other programs from a Python program with the `subprocess` library. Note that this can be used to launch any program, not just other Python programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All processes launched\n",
      "All processes completed\n"
     ]
    }
   ],
   "source": [
    "subprocesses = []\n",
    "for i in range(4):\n",
    "    # start 4 identical copies of the program, and add to list\n",
    "    # note that we could also give them different command line\n",
    "    # arguments by adding more entries in the list of args\n",
    "    # (note that arguments must be strings, not numbers)\n",
    "    args = ['python', '../Python/Parallelisation/wait.py', str(i)]\n",
    "    subprocesses.append( subprocess.Popen(args) )\n",
    "    \n",
    "print('All processes launched')\n",
    "\n",
    "\n",
    "# Wait for all copies to finish before proceeding.\n",
    "# p.wait() does not return until the subprocess is complete.\n",
    "for p in subprocesses:\n",
    "    p.wait()\n",
    "    \n",
    "print('All processes completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping all CPUs busy while running a large number of jobs\n",
    "\n",
    "If you need to run a large number of simulations, it usually makes sense to try to keep all CPUs busy. Say you have 4 CPU cores, then you might want to launch 4 simulations, and as soon as one is finished, you launch another. On Mac and Linux, you can achieve this with the command line tool `xargs` (which I believe is also awailable of modern Windows installations with the Windows subsystem for Linux: https://en.wikipedia.org/wiki/Windows_Subsystem_for_Linux ).\n",
    "\n",
    "However, you might also want to write a python script to do the same thing, since this makes it easy to run simulations for different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 subprocesses running\n",
      "2 subprocesses running\n",
      "3 subprocesses running\n",
      "4 subprocesses running\n",
      "4 subprocesses running\n",
      "4 subprocesses running\n",
      "0 subprocesses running\n",
      "1 subprocesses running\n",
      "2 subprocesses running\n",
      "3 subprocesses running\n",
      "4 subprocesses running\n",
      "4 subprocesses running\n",
      "4 subprocesses running\n",
      "0 subprocesses running\n",
      "1 subprocesses running\n",
      "2 subprocesses running\n",
      "All processes launched\n",
      "All processes completed\n"
     ]
    }
   ],
   "source": [
    "# parameters to run simulation for\n",
    "parameters = [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]\n",
    "# Max simultaneous runs\n",
    "Nprocs = 4\n",
    "\n",
    "# List to keep track of launched processes\n",
    "subprocesses = []\n",
    "# Number currently running\n",
    "running = 0\n",
    "\n",
    "while len(subprocesses) < len(parameters):\n",
    "    # Check if number of simulations currently running\n",
    "    # is smaller than number of processors\n",
    "    if running < Nprocs:\n",
    "        # Start a simulation\n",
    "        i = len(subprocesses)\n",
    "        args = ['python', '../Python/Parallelisation/wait.py', str(parameters[i])]\n",
    "        subprocesses.append( subprocess.Popen(args))\n",
    "    else:\n",
    "        # Wait a few seconds before checking again\n",
    "        sleep(2)\n",
    "        \n",
    "    # Count number of running processes, by creating a boolean\n",
    "    # array with True for running processes and False for completed\n",
    "    # p.poll() returns None if p is still running,\n",
    "    # and 0 if it has excited successfully\n",
    "    running = sum([p.poll() is None for p in subprocesses])\n",
    "    print(f'{running} subprocesses running')\n",
    "\n",
    "print('All processes launched')\n",
    "\n",
    "\n",
    "# Wait for all copies to finish before proceeding.\n",
    "# p.wait() does not return until the subprocess is complete.\n",
    "for p in subprocesses:\n",
    "    p.wait()\n",
    "    \n",
    "print('All processes completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running multiple copies of a function with the Multiprocessing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Pool\n",
    "\n",
    "# For reasons that are not entirely clear to me,\n",
    "# the multiprocessing module seems to have trouble\n",
    "# with functions defined in a notebook. Therefore,\n",
    "# I have defined a function in a separate file\n",
    "# called wait_function.py, which I import here.\n",
    "import sys\n",
    "sys.path.append('../Python/Parallelisation/')\n",
    "import example_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of inputs for which to run simulation\n",
    "parameters = np.arange(12)\n",
    "\n",
    "processes = []\n",
    "\n",
    "for x in parameters:\n",
    "    # the function is defined in the file wait_function.py,\n",
    "    # see comments above\n",
    "    p = Process(target = example_functions.wait_function, args = (x, ))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "# Wait for all copies to finish before proceeding.\n",
    "# p.join() does not return until the process is complete.\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of inputs for which to run simulation\n",
    "parameters = np.arange(12)\n",
    "\n",
    "# Using a pool of 4 processes will keep\n",
    "# 4 copies of the function running at all times,\n",
    "# until the function has been run for each parameter\n",
    "with Pool(4) as pool:\n",
    "    pool.map(example_functions.wait_function, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelisation with Numba\n",
    "\n",
    "Numba has some support for parallelisation. For example you can parallelise loops by using `prange` instead of `range`. Note that this requires that each iteration in the loop is indpenedent of the other iterations.\n",
    "\n",
    "For additional information, see the Numba documentation: https://numba.pydata.org/numba-doc/latest/user/parallel.html#numba-parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def iterator(z, c, maxiter):\n",
    "    for i in range(maxiter):\n",
    "        z = z*z + c\n",
    "        if abs(z) > 2:\n",
    "            return i\n",
    "    return maxiter\n",
    "\n",
    "@jit(nopython = True)\n",
    "def julia_serial(c, Nx, Ny, xmin=-1.5, xmax=1.5, ymin=-1., ymax=1., maxiter=100):\n",
    "    x = np.linspace(xmin, xmax, Nx)\n",
    "    y = np.linspace(ymin, ymax, Ny)\n",
    "    m = np.empty((Nx, Ny))\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            m[i,j] = iterator(z = x[i] + 1j*y[j], c = c, maxiter = maxiter)\n",
    "    return x, y, m\n",
    "\n",
    "@jit(nopython = True, parallel = True)\n",
    "def julia_parallel(c, Nx, Ny, xmin=-1.5, xmax=1.5, ymin=-1., ymax=1., maxiter=100):\n",
    "    x = np.linspace(xmin, xmax, Nx)\n",
    "    y = np.linspace(ymin, ymax, Ny)\n",
    "    m = np.empty((Nx, Ny))\n",
    "    # Note use of prange instead of range\n",
    "    # (requires parallel = True in the @jit decorator)\n",
    "    for i in prange(Nx):\n",
    "        for j in range(Ny):\n",
    "            m[i,j] = iterator(z = x[i] + 1j*y[j], c = c, maxiter = maxiter)\n",
    "    return x, y, m\n",
    "\n",
    "# Force compilation by calling functions here,\n",
    "# to avoid messing up timing later\n",
    "_ = julia_serial(0+1j, 1, 1)\n",
    "_ = julia_parallel(0+1j, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial version:\n",
      "356 ms ± 9.98 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n",
      "Parallel version:\n",
      "98.5 ms ± 2.27 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "Nx = 1500\n",
    "Ny = 1000\n",
    "c = 0.02 + 1j*0.4\n",
    "\n",
    "print('Serial version:')\n",
    "%timeit -n1 -r5 x, y, m = julia_serial(c, Nx, Ny)\n",
    "\n",
    "print('Parallel version:')\n",
    "%timeit -n1 -r5 x, y, m = julia_parallel(c, Nx, Ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def diffusion_serial(C0, D, v, X, T):\n",
    "    # Make a copy to avoid overwriting the initial condition\n",
    "    C = C0.copy()\n",
    "    # Find dx and dt (assuming constant spacing)\n",
    "    dx = X[1] - X[0]\n",
    "    dt = T[1] - T[0]\n",
    "    # Run simulation for each value in T\n",
    "    for i in range(len(T)):\n",
    "        # Make a new empty array to hold the updated values\n",
    "        Cnew = np.empty_like(C)\n",
    "        # Using a for-loop to begin with\n",
    "        # Handle interior points first\n",
    "        for i in range(1, len(C)-1):\n",
    "            Cnew[i] = C[i] + dt*(D*(C[i+1] - 2*C[i] + C[i-1])/dx**2  -  v*(C[i+1] - C[i-1])/(2*dx))\n",
    "        # Then, handle boundary points to get periodic BC\n",
    "        Cnew[ 0] = C[ 0] + dt*(D*(C[1] - 2*C[ 0] + C[-1])/dx**2  -  v*(C[1] - C[-1])/(2*dx))\n",
    "        Cnew[-1] = C[-1] + dt*(D*(C[0] - 2*C[-1] + C[-2])/dx**2  -  v*(C[0] - C[-2])/(2*dx))\n",
    "        # Finally, copy values back into C\n",
    "        C = Cnew\n",
    "    # Return results at\n",
    "    return C\n",
    "\n",
    "@jit(nopython=True, parallel = True)\n",
    "def diffusion_parallel(C0, D, v, X, T):\n",
    "    # Make a copy to avoid overwriting the initial condition\n",
    "    C = C0.copy()\n",
    "    # Find dx and dt (assuming constant spacing)\n",
    "    dx = X[1] - X[0]\n",
    "    dt = T[1] - T[0]\n",
    "    # Run simulation for each value in T\n",
    "    for i in range(len(T)):\n",
    "        # Make a new empty array to hold the updated values\n",
    "        Cnew = np.empty_like(C)\n",
    "        # Using a for-loop to begin with\n",
    "        # Handle interior points first\n",
    "        # Note use of prange instead of range here\n",
    "        for i in prange(1, len(C)-1):\n",
    "            Cnew[i] = C[i] + dt*(D*(C[i+1] - 2*C[i] + C[i-1])/dx**2  -  v*(C[i+1] - C[i-1])/(2*dx))\n",
    "        # Then, handle boundary points to get periodic BC\n",
    "        Cnew[ 0] = C[ 0] + dt*(D*(C[1] - 2*C[ 0] + C[-1])/dx**2  -  v*(C[1] - C[-1])/(2*dx))\n",
    "        Cnew[-1] = C[-1] + dt*(D*(C[0] - 2*C[-1] + C[-2])/dx**2  -  v*(C[0] - C[-2])/(2*dx))\n",
    "        # Finally, copy values back into C\n",
    "        C = Cnew\n",
    "    # Return results at\n",
    "    return C\n",
    "\n",
    "# Force compilation by calling functions here,\n",
    "# to avoid messing up timing later\n",
    "_ = diffusion_serial(np.linspace(0,1,10), 1e-3, 1e-3, np.linspace(0, 1, 10), np.linspace(0, 1, 10))\n",
    "_ = diffusion_parallel(np.linspace(0,1,10), 1e-3, 1e-3, np.linspace(0, 1, 10), np.linspace(0, 1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D dt/dx**2 = 0.5000\n",
      "Serial version:\n",
      "472 ms ± 4.94 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "Parallel version:\n",
      "242 ms ± 16.2 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Set up and run simulation\n",
    "D = 0.0001 # Diffusivity\n",
    "v = 0.01 # Advection velocity\n",
    "T = np.linspace(0, 1, 20001) # time coordinates\n",
    "X = np.linspace(0, 1, 10001) # x coordinates\n",
    "# Initial concentration\n",
    "mu = 0.5\n",
    "sigma = 0.1\n",
    "C0 = (1/(sigma*np.sqrt(2*np.pi))) * np.exp(-(X - mu)**2 / (2*sigma**2))\n",
    "\n",
    "# Check stability (this number should be smaller than 1/2)\n",
    "print(f'D dt/dx**2 = {D*(T[1]-T[0])/(X[1]-X[0])**2:.4f}')\n",
    "\n",
    "print('Serial version:')\n",
    "%timeit -n1 -r3 C = diffusion_serial(C0, D, v, X, T)\n",
    "\n",
    "print('Parallel version:')\n",
    "%timeit -n1 -r3 C = diffusion_parallel(C0, D, v, X, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "CudaSupportError",
     "evalue": "Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCudaSupportError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f869d50616a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36mcurrent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \"\"\"Returns the active device or None if there's no active device\n\u001b[1;32m     54\u001b[0m         \"\"\"\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_active_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mdevnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdevnum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mhctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrvapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcu_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuCtxGetCurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mhctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhctx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialization_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise CudaSupportError(\"Error at driver init: \\n%s:\" %\n\u001b[0m\u001b[1;32m    286\u001b[0m                                    self.initialization_error)\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCudaSupportError\u001b[0m: Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:"
     ]
    }
   ],
   "source": [
    "cuda.gpus.current()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
